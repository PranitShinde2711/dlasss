

    import tensorflow as tf
    import numpy as np
    import pandas as pd

    df=pd.read_csv(r"C:\Users\sumit\Downloads\creditcardfraud-csv\creditcardfraud-csv\creditcard.csv")
    df.drop(['Time','Class'],axis=1)
    df

                Time         V1         V2        V3        V4        V5  \
    0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   
    1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   
    2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   
    3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   
    4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   
    ...          ...        ...        ...       ...       ...       ...   
    284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   
    284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   
    284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   
    284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   
    284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   

                  V6        V7        V8        V9  ...       V21       V22  \
    0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   
    1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   
    2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   
    3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   
    4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   
    ...          ...       ...       ...       ...  ...       ...       ...   
    284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   
    284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   
    284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   
    284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   
    284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   

                 V23       V24       V25       V26       V27       V28  Amount  \
    0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   
    1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   
    2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   
    3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   
    4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   
    ...          ...       ...       ...       ...       ...       ...     ...   
    284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   
    284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   
    284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   
    284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   
    284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   

            Class  
    0           0  
    1           0  
    2           0  
    3           0  
    4           0  
    ...       ...  
    284802      0  
    284803      0  
    284804      0  
    284805      0  
    284806      0  

    [284807 rows x 31 columns]

    from sklearn.model_selection import train_test_split
    x_train,x_test=train_test_split(df,test_size=0.2)

    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense

    #build encoder to compress the data

    encoder=tf.keras.models.Sequential([
        layers.Input(shape=(x_train.shape[1],)),
        layers.Dense(64,activation="relu"),
        layers.Dense(64,activation="relu"),
        layers.Dense(20,activation="relu"),
        
    ])

    #build the decoder to reconstruct the data
    decoder=tf.keras.models.Sequential([
        layers.Input(shape=(20,)),
        layers.Dense(64,activation="relu"),
        layers.Dense(64,activation="relu"),
        layers.Dense(x_train.shape[1],activation="linear"),
        
    ])

    model=tf.keras.Sequential([
        encoder,decoder
    ])

    model.compile(optimizer='adam',loss='mean_squared_error')

    model.fit(x_train,x_train,batch_size=100,epochs=10,validation_data=(x_test,x_test))

    Epoch 1/10
    2279/2279 ━━━━━━━━━━━━━━━━━━━━ 3s 982us/step - loss: 14415461.0000 - val_loss: 449.4842
    Epoch 2/10
    2279/2279 ━━━━━━━━━━━━━━━━━━━━ 2s 901us/step - loss: 987.1739 - val_loss: 148.6423
    Epoch 3/10
    2279/2279 ━━━━━━━━━━━━━━━━━━━━ 2s 917us/step - loss: 3024.1172 - val_loss: 241.3470
    Epoch 4/10
    2279/2279 ━━━━━━━━━━━━━━━━━━━━ 2s 891us/step - loss: 2363.7781 - val_loss: 47.9785
    Epoch 5/10
    2279/2279 ━━━━━━━━━━━━━━━━━━━━ 2s 898us/step - loss: 2797.2234 - val_loss: 69.0454
    Epoch 6/10
    2279/2279 ━━━━━━━━━━━━━━━━━━━━ 2s 896us/step - loss: 1872.4031 - val_loss: 5897.7739
    Epoch 7/10
    2279/2279 ━━━━━━━━━━━━━━━━━━━━ 2s 886us/step - loss: 2602.6086 - val_loss: 194.4091
    Epoch 8/10
    2279/2279 ━━━━━━━━━━━━━━━━━━━━ 2s 896us/step - loss: 2585.7046 - val_loss: 35.8397
    Epoch 9/10
    2279/2279 ━━━━━━━━━━━━━━━━━━━━ 2s 890us/step - loss: 2459.3416 - val_loss: 1021.1338
    Epoch 10/10
    2279/2279 ━━━━━━━━━━━━━━━━━━━━ 2s 908us/step - loss: 2347.8059 - val_loss: 49.9051

    <keras.src.callbacks.history.History at 0x1b202023fb0>

    pred=model.predict(x_test)
    mse=np.mean(np.power(x_test-pred,2),axis=1)

    1781/1781 ━━━━━━━━━━━━━━━━━━━━ 1s 565us/step

    threshold=np.percentile(mse,95)
    anomalies=mse > threshold
    no_anomalies=np.sum(anomalies)
    print(no_anomalies)

    2849

    import matplotlib.pyplot as plt
    plt.plot(x_test.iloc[0],label='Original ECG')
    plt.plot(pred[0],label='Reconstructed ECG')

    [<matplotlib.lines.Line2D at 0x1b205636d80>]

[]

    plt.plot(mse, marker='o', linestyle='', markersize=3, label='MSE')
    plt.axhline(threshold, color='r', linestyle='--', label='Anomaly Threshold')
    plt.xlabel('Sample Index')
    plt.ylabel('MSE')
    plt.title('Anomaly Detection Results')
    plt.legend()
    plt.show()

[]
